import redis
import json
import os
import psycopg2
import boto3
import io
import traceback
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer

# åˆå§‹åŒ–æ¨¡å‹ (é€™æœƒèŠ±ä¸€é»æ™‚é–“ä¸‹è¼‰)
print("Loading Embedding Model...")
model = SentenceTransformer('all-MiniLM-L6-v2') 
print("Model Loaded!")

redis_client = redis.Redis(host=os.getenv("REDIS_HOST"), port=6379, db=0)

def get_db_connection():
    return psycopg2.connect(
        host=os.getenv("DB_HOST"),
        database=os.getenv("DB_NAME"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD")
    )

def get_s3_client():
    return boto3.client(
        's3',
        endpoint_url=f"http://{os.getenv('MINIO_ENDPOINT')}",
        aws_access_key_id=os.getenv("MINIO_ACCESS_KEY"),
        aws_secret_access_key=os.getenv("MINIO_SECRET_KEY")
    )

def process_etl():
    while True:
        # ç›£è½ etl_queue
        item = redis_client.brpop("etl_queue", timeout=0)
        if item:
            task = json.loads(item[1])
            doc_id = task['doc_id']
            s3_key = task['s3_key']
            
            print(f"Processing Document ID: {doc_id}...")
            
            conn = get_db_connection()
            cursor = conn.cursor()
            s3 = get_s3_client()
            bucket = os.getenv("MINIO_BUCKET")
            print(f"ğŸš€ [Start] Processing Document ID: {doc_id}...")

            try:
                # æ›´æ–°ç‹€æ…‹ç‚º processing
                cursor.execute("UPDATE documents SET status = 'processing' WHERE id = %s", (doc_id,))
                conn.commit()

                # 1. ä¸‹è¼‰
                print(f"   Downloading S3 Key: {s3_key}")
                obj = s3.get_object(Bucket=bucket, Key=s3_key)
                file_stream = io.BytesIO(obj['Body'].read())

                # 2. è§£æ PDF
                text_content = ""
                try:
                    print("   Parsing PDF...")
                    pdf = PdfReader(file_stream)
                    # æª¢æŸ¥æ˜¯å¦åŠ å¯†
                    if pdf.is_encrypted:
                        print("   âš ï¸ PDF is encrypted! Trying to decrypt...")
                        try:
                            pdf.decrypt("") # å˜—è©¦ç©ºå¯†ç¢¼
                        except:
                            raise Exception("PDF Encrypted and cannot be read.")
                            
                    for i, page in enumerate(pdf.pages):
                        extracted = page.extract_text()
                        if extracted:
                            text_content += extracted + "\n"
                        else:
                            print(f"   âš ï¸ Page {i} extracted empty text (might be image-only PDF)")

                except Exception as pdf_err:
                    print(f"   âŒ PDF Parse Error: {pdf_err}")
                    # å‚™æ¡ˆï¼šå¦‚æœæ˜¯ç´”æ–‡å­—æª”èª¤å‚³ç‚º PDFï¼Œè©¦è‘—ç”¨ utf-8 ç¡¬è®€
                    file_stream.seek(0)
                    text_content = file_stream.read().decode('utf-8', errors='ignore')

                if not text_content.strip():
                    raise Exception("Extracted text is empty! (File might be image-only PDF or empty)")

                print(f"   âœ… Extracted {len(text_content)} chars.")

                # 3. åˆ‡åˆ†æ–‡å­— (Chunking) 
                # ç°¡å–®åˆ‡åˆ†ï¼šæ¯ 500 å­—åˆ‡ä¸€å¡Šï¼Œé‡ç–Š 50 å­— (é€™æ¯”å–®ç´”æ›è¡Œåˆ‡åˆ†æ›´å¥½)
                chunk_size = 500
                overlap = 50
                chunks = []
                for i in range(0, len(text_content), chunk_size - overlap):
                    chunk = text_content[i:i + chunk_size]
                    if len(chunk) > 50: # å¤ªçŸ­çš„ä¸è¦
                        chunks.append(chunk)
                
                print(f"åˆ‡åˆ†æˆ {len(chunks)} å€‹å€å¡Šï¼Œé–‹å§‹å‘é‡åŒ–...")

                # 4. å‘é‡åŒ– (Embedding)
                if chunks:
                    embeddings = model.encode(chunks)
                    
                    # 5. å­˜å…¥ pgvector
                    for text, vector in zip(chunks, embeddings):
                        cursor.execute(
                            "INSERT INTO document_chunks (document_id, chunk_text, embedding) VALUES (%s, %s, %s)",
                            (doc_id, text, vector.tolist())
                        )
                
                # æ›´æ–°ç‹€æ…‹ç‚º completed
                cursor.execute("UPDATE documents SET status = 'completed' WHERE id = %s", (doc_id,))
                conn.commit()
                print(f"Document {doc_id} processed successfully.")

            except Exception as e:
                print(f"Error: {e}")
                cursor.execute("UPDATE documents SET status = 'failed' WHERE id = %s", (doc_id,))
                conn.commit()
            finally:
                cursor.close()
                conn.close()

if __name__ == "__main__":
    process_etl()